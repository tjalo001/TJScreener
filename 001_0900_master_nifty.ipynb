{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## program 1. earning calender for the stock for the day along with MIS/ ASM status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available dates:\n",
      "1. 10-Aug-2024\n",
      "2. 11-Aug-2024\n",
      "3. 12-Aug-2024\n",
      "4. 13-Aug-2024\n",
      "5. 14-Aug-2024\n",
      "Index(['SYMBOL \\n', 'OPEN \\n', 'HIGH \\n', 'LOW \\n', 'PREV. CLOSE \\n', 'LTP \\n',\n",
      "       'CHNG \\n', '%CHNG \\n', 'VOLUME \\n(shares)', 'VALUE \\n (â‚¹ Crores)',\n",
      "       '52W H \\n', '52W L \\n', '30 D   %CHNG \\n',\n",
      "       '365 D % CHNG \\n 27-Jul-2023'],\n",
      "      dtype='object')\n",
      "Data saved to earnings_calendar_with_mis_and_fo.xlsx\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from openpyxl import Workbook, load_workbook\n",
    "from openpyxl.styles import Font, PatternFill\n",
    "from datetime import datetime\n",
    "\n",
    "# Define the URL and headers\n",
    "url = \"https://www.nseindia.com/api/event-calendar\"\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3',\n",
    "    'Accept-Language': 'en-US,en;q=0.5',\n",
    "    'Accept-Encoding': 'gzip, deflate, br',\n",
    "    'Connection': 'keep-alive'\n",
    "}\n",
    "\n",
    "# Initialize session to manage cookies\n",
    "session = requests.Session()\n",
    "\n",
    "def fetch_earnings_calendar(url):\n",
    "    try:\n",
    "        # Make a GET request to the main page to establish the session\n",
    "        session.get('https://www.nseindia.com', headers=headers)\n",
    "        \n",
    "        # Now, make the request to the API endpoint\n",
    "        response = session.get(url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        earnings_data = response.json()\n",
    "        \n",
    "        # Extract relevant fields: symbol, date, purpose\n",
    "        parsed_data = [\n",
    "            {\n",
    "                'symbol': item['symbol'],\n",
    "                'Result_date': item['date'],\n",
    "                'Purpose': item['purpose']\n",
    "            }\n",
    "            for item in earnings_data\n",
    "        ]\n",
    "        \n",
    "        return pd.DataFrame(parsed_data)\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching earnings calendar: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Load the pre-saved Excel file and extract the data from 'MIS' sheet\n",
    "def load_mis_data(filename):\n",
    "    mis_df = pd.read_excel(filename, sheet_name='MIS')\n",
    "    return mis_df\n",
    "\n",
    "# Add the MIS Margin allowed column based on the symbol match\n",
    "def add_mis_margin(df, mis_df):\n",
    "    # Use merge to join on 'symbol' and 'Stocks allowed for MIS'\n",
    "    merged_df = df.merge(mis_df, left_on='symbol', right_on='Stocks allowed for MIS', how='left')\n",
    "    # Rename the column for clarity\n",
    "    merged_df.rename(columns={'Margin allowed': 'MIS Margin allowed'}, inplace=True)\n",
    "    # Fill missing values with \"ASM\"\n",
    "    merged_df['MIS Margin allowed'] = merged_df['MIS Margin allowed'].fillna('ASM')\n",
    "    # Drop the duplicate 'Stocks allowed for MIS' column if needed\n",
    "    merged_df = merged_df.drop(columns=['Stocks allowed for MIS'])\n",
    "    return merged_df\n",
    "\n",
    "def apply_styles(ws, fo_symbols, n=5, threshold_high=3, threshold_mid=1):\n",
    "    header_font = Font(bold=True)\n",
    "    for cell in ws[\"1:1\"]:\n",
    "        cell.font = header_font\n",
    "        cell.fill = PatternFill(start_color=\"FFFF00\", end_color=\"FFFF00\", fill_type=\"solid\")\n",
    "\n",
    "    for col in ws.columns:\n",
    "        max_length = 0\n",
    "        column = col[0].column_letter\n",
    "        for cell in col:\n",
    "            try:\n",
    "                if len(str(cell.value)) > max_length:\n",
    "                    max_length = len(cell.value)\n",
    "            except:\n",
    "                pass\n",
    "        adjusted_width = (max_length + 2)\n",
    "        ws.column_dimensions[column].width = adjusted_width\n",
    "\n",
    "    ws.auto_filter.ref = ws.dimensions\n",
    "    ws.freeze_panes = ws['E2']\n",
    "\n",
    "    # Identify all pChange columns\n",
    "    pchange_columns = [cell.column_letter for cell in ws[1] if cell.value and 'pChange' in cell.value]\n",
    "\n",
    "    # Apply color coding to pChange columns and highlight F&O symbols\n",
    "    for i, row in enumerate(ws.iter_rows(min_row=2, max_row=ws.max_row), start=2):\n",
    "        for cell in row:\n",
    "            if cell.column_letter in pchange_columns:\n",
    "                if cell.value is not None:\n",
    "                    if cell.value > 0:\n",
    "                        if cell.value > threshold_high:\n",
    "                            cell.fill = PatternFill(start_color=\"00FF00\", end_color=\"00FF00\", fill_type=\"solid\")  # Bright green\n",
    "                        elif cell.value > threshold_mid:\n",
    "                            cell.fill = PatternFill(start_color=\"66FF66\", end_color=\"66FF66\", fill_type=\"solid\")  # Medium green\n",
    "                        else:\n",
    "                            cell.fill = PatternFill(start_color=\"99FF99\", end_color=\"99FF99\", fill_type=\"solid\")  # Light green\n",
    "                    elif cell.value < 0:\n",
    "                        cell.fill = PatternFill(start_color=\"FF0000\", end_color=\"FF0000\", fill_type=\"solid\")\n",
    "\n",
    "            # Highlight F&O symbols\n",
    "            if cell.column_letter == 'A' and cell.value in fo_symbols:\n",
    "                for highlight_cell in row:\n",
    "                    highlight_cell.fill = PatternFill(start_color=\"FFFF00\", end_color=\"FFFF00\", fill_type=\"solid\")\n",
    "\n",
    "            # Apply new color coding to every nth row\n",
    "            if (i - 1) % n == 0:\n",
    "                cell.fill = PatternFill(start_color=\"ADD8E6\", end_color=\"ADD8E6\", fill_type=\"solid\")  # Light blue color\n",
    "\n",
    "# Fetch F&O symbols from CSV\n",
    "def fetch_fo_list_from_csv(file_path):\n",
    "    try:\n",
    "        fo_symbols_df = pd.read_csv(file_path)\n",
    "        print(fo_symbols_df.columns)  # Debugging to check the columns\n",
    "        fo_symbols_df.columns = fo_symbols_df.columns.str.strip()  # Strip any spaces from column names\n",
    "        fo_symbols = fo_symbols_df['SYMBOL'].tolist()  # Adjusting based on actual column name\n",
    "        return fo_symbols\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching F&O symbols: {e}\")\n",
    "        return []\n",
    "        \n",
    "# Fetch the earnings calendar data\n",
    "earnings_df = fetch_earnings_calendar(url)\n",
    "if earnings_df.empty:\n",
    "    print(\"No earnings data fetched.\")\n",
    "    exit()\n",
    "\n",
    "# List available dates (restricted to first five)\n",
    "unique_dates = earnings_df['Result_date'].unique()[:5]\n",
    "print(\"Available dates:\")\n",
    "for i, date in enumerate(unique_dates, start=1):\n",
    "    print(f\"{i}. {date}\")\n",
    "\n",
    "# Ask user to input the dates for specific sheets\n",
    "selected_dates = []\n",
    "for i in range(1, 6):\n",
    "    date_index = int(input(f\"Enter the serial number of the date you want to save to Sheet {i}: \")) - 1\n",
    "    if date_index not in range(5):\n",
    "        print(\"Invalid input. Please run the script again and enter valid serial numbers.\")\n",
    "        exit()\n",
    "    selected_dates.append(unique_dates[date_index])\n",
    "\n",
    "# Load the MIS data\n",
    "mis_filename = '/Users/tjzoomac/tj_nse/ai_market/01_nifty_live/002/fixed_files_getto/rms.xlsx'\n",
    "mis_data = load_mis_data(mis_filename)\n",
    "\n",
    "# Load F&O symbols from CSV\n",
    "fo_csv_path ='/Users/tjzoomac/tj_nse/ai_market/01_nifty_live/002/fixed_files_getto//MW-SECURITIES-IN-F&O-28-Jul-2024.csv'  # Update with your actual CSV file path\n",
    "fo_symbols = fetch_fo_list_from_csv(fo_csv_path)\n",
    "\n",
    "# Create a writer to save data to Excel file with a timestamp\n",
    "timestamp = datetime.now().strftime(\"%d%b\")\n",
    "filename = f'{timestamp}_0900_earnings_calendar_with_mis_and_fo.xlsx'\n",
    "excel_writer = pd.ExcelWriter(filename, engine='openpyxl')\n",
    "# # Create a writer to save data to Excel file\n",
    "# excel_writer = pd.ExcelWriter('0900_earnings_calendar_with_mis_and_fo.xlsx', engine='openpyxl')\n",
    "\n",
    "# Save data for each selected date in a separate sheet\n",
    "for i, date in enumerate(selected_dates, start=1):\n",
    "    filtered_df = earnings_df[earnings_df['Result_date'] == date]\n",
    "    filtered_df = add_mis_margin(filtered_df, mis_data)  # Add MIS margin data\n",
    "    sheet_name = f\"Sheet{i}_{date.replace('-', '_')}\"\n",
    "    filtered_df.to_excel(excel_writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "    # Apply styles\n",
    "    wb = excel_writer.book\n",
    "    ws = wb[sheet_name]\n",
    "    apply_styles(ws, fo_symbols)\n",
    "\n",
    "# Save the Excel file using close() method\n",
    "excel_writer.close()\n",
    "print(\"Data saved to earnings_calendar_with_mis_and_fo.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available sheets:\n",
      "1. Sheet1_14_Aug_2024\n",
      "2. Sheet2_10_Aug_2024\n",
      "3. Sheet3_11_Aug_2024\n",
      "4. Sheet4_12_Aug_2024\n",
      "5. Sheet5_13_Aug_2024\n",
      "6. Sheet6_14_Aug_2024\n",
      "Data successfully saved to /Users/tjzoomac/tj_nse/ai_market/01_nifty_live/002/09Aug_0900_earnings_calendar_with_mis_and_fo_updated_09Aug2024_0318.xlsx\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from openpyxl import load_workbook, Workbook\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "from openpyxl.styles import Font, PatternFill\n",
    "from datetime import datetime\n",
    "\n",
    "# Define the URL and headers\n",
    "base_url = \"https://www.nseindia.com/api/equity-stockIndices?index=NIFTY%20TOTAL%20MARKET\"\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3',\n",
    "    'Accept-Language': 'en-US,en;q=0.5',\n",
    "    'Accept-Encoding': 'gzip, deflate, br',\n",
    "    'Connection': 'keep-alive'\n",
    "}\n",
    "\n",
    "# Initialize session to manage cookies\n",
    "session = requests.Session()\n",
    "\n",
    "def establish_session():\n",
    "    try:\n",
    "        # Access the NSE homepage to establish the session\n",
    "        session.get('https://www.nseindia.com', headers=headers)\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error establishing session: {e}\")\n",
    "\n",
    "def fetch_stock_data(symbol):\n",
    "    try:\n",
    "        response = session.get(base_url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        stock_data = response.json()['data']\n",
    "        \n",
    "        for item in stock_data:\n",
    "            if item['symbol'] == symbol:\n",
    "                # Extract the required data fields\n",
    "                return {\n",
    "                    'symbol': item['symbol'],\n",
    "                    'open': item.get('open', ''),\n",
    "                    'dayHigh': item.get('dayHigh', ''),\n",
    "                    'dayLow': item.get('dayLow', ''),\n",
    "                    'lastPrice': item.get('lastPrice', ''),\n",
    "                    'previousClose': item.get('previousClose', ''),\n",
    "                    'pChange': item.get('pChange', ''),\n",
    "                    'totalTradedVolume': item.get('totalTradedVolume', ''),\n",
    "                    'yearHigh': item.get('yearHigh', ''),\n",
    "                    'nearWKH': item.get('nearWKH', ''),\n",
    "                    'perChange30d': item.get('perChange30d', ''),\n",
    "                    'industry': item['meta'].get('industry', '')\n",
    "                }\n",
    "        return None\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching stock data for {symbol}: {e}\")\n",
    "        return None\n",
    "\n",
    "def apply_styles(ws, fo_symbols=[], n=5, threshold_high=3, threshold_mid=1):\n",
    "    header_font = Font(bold=True)\n",
    "    for cell in ws[\"1:1\"]:\n",
    "        cell.font = header_font\n",
    "        cell.fill = PatternFill(start_color=\"FFFF00\", end_color=\"FFFF00\", fill_type=\"solid\")\n",
    "\n",
    "    for col in ws.columns:\n",
    "        max_length = 0\n",
    "        column = col[0].column_letter\n",
    "        for cell in col:\n",
    "            try:\n",
    "                if len(str(cell.value)) > max_length:\n",
    "                    max_length = len(cell.value)\n",
    "            except:\n",
    "                pass\n",
    "        adjusted_width = (max_length + 2)\n",
    "        ws.column_dimensions[column].width = adjusted_width\n",
    "\n",
    "    ws.auto_filter.ref = ws.dimensions\n",
    "    ws.freeze_panes = ws['E2']\n",
    "\n",
    "    # Identify all pChange columns\n",
    "    pchange_columns = [cell.column_letter for cell in ws[1] if cell.value and 'pChange' in cell.value]\n",
    "\n",
    "    # Apply color coding to pChange columns and highlight F&O symbols\n",
    "    for i, row in enumerate(ws.iter_rows(min_row=2, max_row=ws.max_row), start=2):\n",
    "        for cell in row:\n",
    "            if cell.column_letter in pchange_columns:\n",
    "                if cell.value is not None:\n",
    "                    try:\n",
    "                        cell_value = float(cell.value)\n",
    "                        if cell_value > 0:\n",
    "                            if cell_value > threshold_high:\n",
    "                                cell.fill = PatternFill(start_color=\"00FF00\", end_color=\"00FF00\", fill_type=\"solid\")  # Bright green\n",
    "                            elif cell_value > threshold_mid:\n",
    "                                cell.fill = PatternFill(start_color=\"66FF66\", end_color=\"66FF66\", fill_type=\"solid\")  # Medium green\n",
    "                            else:\n",
    "                                cell.fill = PatternFill(start_color=\"99FF99\", end_color=\"99FF99\", fill_type=\"solid\")  # Light green\n",
    "                        elif cell_value < 0:\n",
    "                            cell.fill = PatternFill(start_color=\"FF0000\", end_color=\"FF0000\", fill_type=\"solid\")\n",
    "                    except ValueError:\n",
    "                        # If the cell value cannot be converted to float, skip it\n",
    "                        continue\n",
    "\n",
    "            # Highlight F&O symbols\n",
    "            if cell.column_letter == 'A' and cell.value in fo_symbols:\n",
    "                for highlight_cell in row:\n",
    "                    highlight_cell.fill = PatternFill(start_color=\"FFFF00\", end_color=\"FFFF00\", fill_type=\"solid\")\n",
    "\n",
    "            # Apply new color coding to every nth row\n",
    "            if (i - 1) % n == 0:\n",
    "                cell.fill = PatternFill(start_color=\"ADD8E6\", end_color=\"ADD8E6\", fill_type=\"solid\")  # Light blue color\n",
    "\n",
    "def update_excel_sheets(file_path):\n",
    "    # Load the workbook and get all sheet names\n",
    "    wb = load_workbook(file_path)\n",
    "    sheets = wb.sheetnames\n",
    "\n",
    "    # Prompt user to select the sheet for which data needs to be fetched\n",
    "    print(\"Available sheets:\")\n",
    "    for i, sheet in enumerate(sheets, start=1):\n",
    "        print(f\"{i}. {sheet}\")\n",
    "    \n",
    "    sheet_index = int(input(\"Enter the serial number of the sheet you want to update: \")) - 1\n",
    "    if sheet_index not in range(len(sheets)):\n",
    "        print(\"Invalid input. Please run the script again and enter a valid serial number.\")\n",
    "        return\n",
    "    \n",
    "    selected_sheet_name = sheets[sheet_index]\n",
    "\n",
    "    # Create a new workbook to save the updated data\n",
    "    new_wb = Workbook()\n",
    "    new_wb.remove(new_wb.active)  # Remove the default sheet\n",
    "\n",
    "    ws = wb[selected_sheet_name]\n",
    "    df = pd.DataFrame(ws.values)\n",
    "\n",
    "    # Extract the symbol column (assuming it's in the first column)\n",
    "    symbols = df[0].dropna().values[1:]  # Skip header\n",
    "\n",
    "    # List to store new rows\n",
    "    new_rows = []\n",
    "\n",
    "    for symbol in symbols:\n",
    "        stock_data = fetch_stock_data(symbol)\n",
    "        if stock_data:\n",
    "            new_row = [\n",
    "                stock_data['symbol'],\n",
    "                stock_data['open'],\n",
    "                stock_data['dayHigh'],\n",
    "                stock_data['dayLow'],\n",
    "                stock_data['lastPrice'],\n",
    "                stock_data['previousClose'],\n",
    "                stock_data['pChange'],\n",
    "                stock_data['totalTradedVolume'],\n",
    "                stock_data['yearHigh'],\n",
    "                stock_data['nearWKH'],\n",
    "                stock_data['perChange30d'],\n",
    "                stock_data['industry']\n",
    "            ]\n",
    "        else:\n",
    "            # Maintain data integrity by adding an empty row if data is not found\n",
    "            new_row = [''] * 12\n",
    "        new_rows.append(new_row)\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    new_df = pd.DataFrame(new_rows, columns=[\n",
    "        'symbol', 'open', 'dayHigh', 'dayLow', 'lastPrice', 'previousClose',\n",
    "        'pChange', 'totalTradedVolume', 'yearHigh', 'nearWKH', 'perChange30d', 'industry'\n",
    "    ])\n",
    "\n",
    "    # Append to the right of existing data\n",
    "    for r_idx, row in enumerate(dataframe_to_rows(new_df, index=False, header=True), 1):\n",
    "        for c_idx, value in enumerate(row, len(df.columns) + 1):\n",
    "            ws.cell(row=r_idx, column=c_idx, value=value)\n",
    "\n",
    "    # Add the sheet with updated data to the new workbook\n",
    "    new_ws = new_wb.create_sheet(selected_sheet_name)\n",
    "    for row in ws.iter_rows(values_only=True):\n",
    "        new_ws.append(row)\n",
    "\n",
    "    # Apply styles to the newly appended data\n",
    "    apply_styles(new_ws, fo_symbols=[])\n",
    "\n",
    "    # Generate the new file path\n",
    "    timestamp = datetime.now().strftime(\"%d%b%Y_%H%M\")\n",
    "    new_file_path = f\"{file_path.split('.xlsx')[0]}_updated_{timestamp}.xlsx\"\n",
    "\n",
    "    # Save the new workbook\n",
    "    new_wb.save(new_file_path)\n",
    "    print(f\"Data successfully saved to {new_file_path}\")\n",
    "\n",
    "# Establish the session\n",
    "establish_session()\n",
    "\n",
    "# Specify the Excel file path\n",
    "file_path = '/Users/tjzoomac/tj_nse/ai_market/01_nifty_live/002/09Aug_0900_earnings_calendar_with_mis_and_fo.xlsx'\n",
    "\n",
    "# Update the selected sheet and save the new workbook\n",
    "update_excel_sheets(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully appended to /Users/tjzoomac/tj_nse/ai_market/01_nifty_live/002/database/Aug_24/7 Aug 24/07Aug_0900_earnings_calendar_with_mis_and_fo.xlsx in sheet Sheet2_09_Aug_2024.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "from datetime import datetime\n",
    "\n",
    "# Define the URL and headers\n",
    "base_url = \"https://www.nseindia.com/api/equity-stockIndices?index=NIFTY%20TOTAL%20MARKET\"\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3',\n",
    "    'Accept-Language': 'en-US,en;q=0.5',\n",
    "    'Accept-Encoding': 'gzip, deflate, br',\n",
    "    'Connection': 'keep-alive'\n",
    "}\n",
    "\n",
    "# Initialize session to manage cookies\n",
    "session = requests.Session()\n",
    "\n",
    "def establish_session():\n",
    "    try:\n",
    "        # Access the NSE homepage to establish the session\n",
    "        session.get('https://www.nseindia.com', headers=headers)\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error establishing session: {e}\")\n",
    "\n",
    "def fetch_stock_data(symbol):\n",
    "    try:\n",
    "        response = session.get(base_url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        stock_data = response.json()['data']\n",
    "        \n",
    "        for item in stock_data:\n",
    "            if item['symbol'] == symbol:\n",
    "                # Extract the required data fields\n",
    "                return {\n",
    "                    'symbol': item['symbol'],\n",
    "                    'open': item.get('open', ''),\n",
    "                    'dayHigh': item.get('dayHigh', ''),\n",
    "                    'dayLow': item.get('dayLow', ''),\n",
    "                    'lastPrice': item.get('lastPrice', ''),\n",
    "                    'previousClose': item.get('previousClose', ''),\n",
    "                    'pChange': item.get('pChange', ''),\n",
    "                    'totalTradedVolume': item.get('totalTradedVolume', ''),\n",
    "                    'yearHigh': item.get('yearHigh', ''),\n",
    "                    'nearWKH': item.get('nearWKH', ''),\n",
    "                    'perChange30d': item.get('perChange30d', ''),\n",
    "                    'industry': item['meta'].get('industry', '')\n",
    "                }\n",
    "        return None\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching stock data for {symbol}: {e}\")\n",
    "        return None\n",
    "\n",
    "def update_excel_sheet(file_path, sheet_name):\n",
    "    # Load the workbook and the selected sheet\n",
    "    wb = load_workbook(file_path)\n",
    "    if sheet_name not in wb.sheetnames:\n",
    "        print(f\"Sheet {sheet_name} not found in the workbook.\")\n",
    "        return\n",
    "    \n",
    "    ws = wb[sheet_name]\n",
    "    df = pd.DataFrame(ws.values)\n",
    "\n",
    "    # Extract the symbol column (assuming it's in the first column)\n",
    "    symbols = df[0].dropna().values[1:]  # Skip header\n",
    "\n",
    "    # List to store new rows\n",
    "    new_rows = []\n",
    "\n",
    "    for symbol in symbols:\n",
    "        stock_data = fetch_stock_data(symbol)\n",
    "        if stock_data:\n",
    "            new_row = [\n",
    "                stock_data['symbol'],\n",
    "                stock_data['open'],\n",
    "                stock_data['dayHigh'],\n",
    "                stock_data['dayLow'],\n",
    "                stock_data['lastPrice'],\n",
    "                stock_data['previousClose'],\n",
    "                stock_data['pChange'],\n",
    "                stock_data['totalTradedVolume'],\n",
    "                stock_data['yearHigh'],\n",
    "                stock_data['nearWKH'],\n",
    "                stock_data['perChange30d'],\n",
    "                stock_data['industry']\n",
    "            ]\n",
    "            new_rows.append(new_row)\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    new_df = pd.DataFrame(new_rows, columns=[\n",
    "        'symbol', 'open', 'dayHigh', 'dayLow', 'lastPrice', 'previousClose',\n",
    "        'pChange', 'totalTradedVolume', 'yearHigh', 'nearWKH', 'perChange30d', 'industry'\n",
    "    ])\n",
    "\n",
    "    # Append to the right of existing data\n",
    "    for r_idx, row in enumerate(dataframe_to_rows(new_df, index=False, header=True), 1):\n",
    "        for c_idx, value in enumerate(row, len(df.columns) + 1):\n",
    "            ws.cell(row=r_idx, column=c_idx, value=value)\n",
    "\n",
    "    # Save the updated workbook\n",
    "    wb.save(file_path)\n",
    "    print(f\"Data successfully appended to {file_path} in sheet {sheet_name}.\")\n",
    "\n",
    "# Establish the session\n",
    "establish_session()\n",
    "\n",
    "\n",
    "# Specify the Excel file path and the sheet to update\n",
    "file_path = '/Users/tjzoomac/tj_nse/ai_market/01_nifty_live/002/database/Aug_24/7 Aug 24/07Aug_0900_earnings_calendar_with_mis_and_fo.xlsx'\n",
    "sheet_name = 'Sheet2_09_Aug_2024'  # Update this to the actual sheet name\n",
    "\n",
    "update_excel_sheet(file_path, sheet_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available sheets:\n",
      "1. Sheet1_09_Aug_2024\n",
      "2. Sheet2_10_Aug_2024\n",
      "3. Sheet3_11_Aug_2024\n",
      "4. Sheet4_12_Aug_2024\n",
      "5. Sheet5_13_Aug_2024\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 173\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# Specify the Excel file path\u001b[39;00m\n\u001b[1;32m    171\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/tjzoomac/tj_nse/ai_market/01_nifty_live/002/database/Aug_24/8 Aug 24/08Aug_0900_earnings_calendar_with_mis_and_fo.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mupdate_excel_sheet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 161\u001b[0m, in \u001b[0;36mupdate_excel_sheet\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m    158\u001b[0m         ws\u001b[38;5;241m.\u001b[39mcell(row\u001b[38;5;241m=\u001b[39mr_idx, column\u001b[38;5;241m=\u001b[39mc_idx, value\u001b[38;5;241m=\u001b[39mvalue)\n\u001b[1;32m    160\u001b[0m \u001b[38;5;66;03m# Apply styles to the newly appended data\u001b[39;00m\n\u001b[0;32m--> 161\u001b[0m \u001b[43mapply_styles\u001b[49m\u001b[43m(\u001b[49m\u001b[43mws\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfo_symbols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;66;03m# Save the updated workbook\u001b[39;00m\n\u001b[1;32m    164\u001b[0m wb\u001b[38;5;241m.\u001b[39msave(file_path)\n",
      "Cell \u001b[0;32mIn[15], line 84\u001b[0m, in \u001b[0;36mapply_styles\u001b[0;34m(ws, fo_symbols, n, threshold_high, threshold_mid)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cell\u001b[38;5;241m.\u001b[39mcolumn_letter \u001b[38;5;129;01min\u001b[39;00m pchange_columns:\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cell\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 84\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcell\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m:\n\u001b[1;32m     85\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m cell\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m>\u001b[39m threshold_high:\n\u001b[1;32m     86\u001b[0m                 cell\u001b[38;5;241m.\u001b[39mfill \u001b[38;5;241m=\u001b[39m PatternFill(start_color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m00FF00\u001b[39m\u001b[38;5;124m\"\u001b[39m, end_color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m00FF00\u001b[39m\u001b[38;5;124m\"\u001b[39m, fill_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msolid\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Bright green\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: '>' not supported between instances of 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "from datetime import datetime\n",
    "from openpyxl.styles import Font, PatternFill\n",
    "\n",
    "# Define the URL and headers\n",
    "base_url = \"https://www.nseindia.com/api/equity-stockIndices?index=NIFTY%20TOTAL%20MARKET\"\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3',\n",
    "    'Accept-Language': 'en-US,en;q=0.5',\n",
    "    'Accept-Encoding': 'gzip, deflate, br',\n",
    "    'Connection': 'keep-alive'\n",
    "}\n",
    "\n",
    "# Initialize session to manage cookies\n",
    "session = requests.Session()\n",
    "\n",
    "def establish_session():\n",
    "    try:\n",
    "        # Access the NSE homepage to establish the session\n",
    "        session.get('https://www.nseindia.com', headers=headers)\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error establishing session: {e}\")\n",
    "\n",
    "def fetch_stock_data(symbol):\n",
    "    try:\n",
    "        response = session.get(base_url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        stock_data = response.json()['data']\n",
    "        \n",
    "        for item in stock_data:\n",
    "            if item['symbol'] == symbol:\n",
    "                # Extract the required data fields\n",
    "                return {\n",
    "                    'symbol': item['symbol'],\n",
    "                    'open': item.get('open', ''),\n",
    "                    'dayHigh': item.get('dayHigh', ''),\n",
    "                    'dayLow': item.get('dayLow', ''),\n",
    "                    'lastPrice': item.get('lastPrice', ''),\n",
    "                    'previousClose': item.get('previousClose', ''),\n",
    "                    'pChange': item.get('pChange', ''),\n",
    "                    'totalTradedVolume': item.get('totalTradedVolume', ''),\n",
    "                    'yearHigh': item.get('yearHigh', ''),\n",
    "                    'nearWKH': item.get('nearWKH', ''),\n",
    "                    'perChange30d': item.get('perChange30d', ''),\n",
    "                    'industry': item['meta'].get('industry', '')\n",
    "                }\n",
    "        return None\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching stock data for {symbol}: {e}\")\n",
    "        return None\n",
    "\n",
    "def apply_styles(ws, fo_symbols, n=5, threshold_high=3, threshold_mid=1):\n",
    "    header_font = Font(bold=True)\n",
    "    for cell in ws[\"1:1\"]:\n",
    "        cell.font = header_font\n",
    "        cell.fill = PatternFill(start_color=\"FFFF00\", end_color=\"FFFF00\", fill_type=\"solid\")\n",
    "\n",
    "    for col in ws.columns:\n",
    "        max_length = 0\n",
    "        column = col[0].column_letter\n",
    "        for cell in col:\n",
    "            try:\n",
    "                if len(str(cell.value)) > max_length:\n",
    "                    max_length = len(cell.value)\n",
    "            except:\n",
    "                pass\n",
    "        adjusted_width = (max_length + 2)\n",
    "        ws.column_dimensions[column].width = adjusted_width\n",
    "\n",
    "    ws.auto_filter.ref = ws.dimensions\n",
    "    ws.freeze_panes = ws['E2']\n",
    "\n",
    "    # Identify all pChange columns\n",
    "    pchange_columns = [cell.column_letter for cell in ws[1] if cell.value and 'pChange' in cell.value]\n",
    "\n",
    "    # Apply color coding to pChange columns and highlight F&O symbols\n",
    "    for i, row in enumerate(ws.iter_rows(min_row=2, max_row=ws.max_row), start=2):\n",
    "        for cell in row:\n",
    "            if cell.column_letter in pchange_columns:\n",
    "                if cell.value is not None:\n",
    "                    if cell.value > 0:\n",
    "                        if cell.value > threshold_high:\n",
    "                            cell.fill = PatternFill(start_color=\"00FF00\", end_color=\"00FF00\", fill_type=\"solid\")  # Bright green\n",
    "                        elif cell.value > threshold_mid:\n",
    "                            cell.fill = PatternFill(start_color=\"66FF66\", end_color=\"66FF66\", fill_type=\"solid\")  # Medium green\n",
    "                        else:\n",
    "                            cell.fill = PatternFill(start_color=\"99FF99\", end_color=\"99FF99\", fill_type=\"solid\")  # Light green\n",
    "                    elif cell.value < 0:\n",
    "                        cell.fill = PatternFill(start_color=\"FF0000\", end_color=\"FF0000\", fill_type=\"solid\")\n",
    "\n",
    "            # Highlight F&O symbols\n",
    "            if cell.column_letter == 'A' and cell.value in fo_symbols:\n",
    "                for highlight_cell in row:\n",
    "                    highlight_cell.fill = PatternFill(start_color=\"FFFF00\", end_color=\"FFFF00\", fill_type=\"solid\")\n",
    "\n",
    "            # Apply new color coding to every nth row\n",
    "            if (i - 1) % n == 0:\n",
    "                cell.fill = PatternFill(start_color=\"ADD8E6\", end_color=\"ADD8E6\", fill_type=\"solid\")  # Light blue color\n",
    "\n",
    "def update_excel_sheet(file_path):\n",
    "    # Load the workbook and list sheet names\n",
    "    wb = load_workbook(file_path)\n",
    "    sheets = wb.sheetnames\n",
    "    print(\"Available sheets:\")\n",
    "    for i, sheet in enumerate(sheets, start=1):\n",
    "        print(f\"{i}. {sheet}\")\n",
    "    \n",
    "    # Prompt user to select a sheet\n",
    "    sheet_index = int(input(\"Enter the serial number of the sheet you want to update: \")) - 1\n",
    "    if sheet_index not in range(len(sheets)):\n",
    "        print(\"Invalid input. Please run the script again and enter a valid serial number.\")\n",
    "        return\n",
    "    \n",
    "    sheet_name = sheets[sheet_index]\n",
    "    ws = wb[sheet_name]\n",
    "    df = pd.DataFrame(ws.values)\n",
    "\n",
    "    # Extract the symbol column (assuming it's in the first column)\n",
    "    symbols = df[0].dropna().values[1:]  # Skip header\n",
    "\n",
    "    # List to store new rows\n",
    "    new_rows = []\n",
    "\n",
    "    for symbol in symbols:\n",
    "        stock_data = fetch_stock_data(symbol)\n",
    "        if stock_data:\n",
    "            new_row = [\n",
    "                stock_data['symbol'],\n",
    "                stock_data['open'],\n",
    "                stock_data['dayHigh'],\n",
    "                stock_data['dayLow'],\n",
    "                stock_data['lastPrice'],\n",
    "                stock_data['previousClose'],\n",
    "                stock_data['pChange'],\n",
    "                stock_data['totalTradedVolume'],\n",
    "                stock_data['yearHigh'],\n",
    "                stock_data['nearWKH'],\n",
    "                stock_data['perChange30d'],\n",
    "                stock_data['industry']\n",
    "            ]\n",
    "        else:\n",
    "            # Maintain data integrity by adding an empty row if data is not found\n",
    "            new_row = [''] * 12\n",
    "        new_rows.append(new_row)\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    new_df = pd.DataFrame(new_rows, columns=[\n",
    "        'symbol', 'open', 'dayHigh', 'dayLow', 'lastPrice', 'previousClose',\n",
    "        'pChange', 'totalTradedVolume', 'yearHigh', 'nearWKH', 'perChange30d', 'industry'\n",
    "    ])\n",
    "\n",
    "    # Append to the right of existing data\n",
    "    for r_idx, row in enumerate(dataframe_to_rows(new_df, index=False, header=True), 1):\n",
    "        for c_idx, value in enumerate(row, len(df.columns) + 1):\n",
    "            ws.cell(row=r_idx, column=c_idx, value=value)\n",
    "\n",
    "    # Apply styles to the newly appended data\n",
    "    apply_styles(ws, fo_symbols=[])\n",
    "\n",
    "    # Save the updated workbook\n",
    "    wb.save(file_path)\n",
    "    print(f\"Data successfully appended to {file_path} in sheet {sheet_name}.\")\n",
    "\n",
    "# Establish the session\n",
    "establish_session()\n",
    "\n",
    "# Specify the Excel file path\n",
    "file_path = '/Users/tjzoomac/tj_nse/ai_market/01_nifty_live/002/database/Aug_24/8 Aug 24/08Aug_0900_earnings_calendar_with_mis_and_fo.xlsx'\n",
    "\n",
    "update_excel_sheet(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available dates:\n",
      "1. 10-Aug-2024\n",
      "2. 11-Aug-2024\n",
      "3. 12-Aug-2024\n",
      "4. 13-Aug-2024\n",
      "5. 14-Aug-2024\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 226\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, date \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(selected_dates, start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    225\u001b[0m     sheet_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSheet\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdate\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 226\u001b[0m     \u001b[43mupdate_excel_sheet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfo_symbols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData saved to earnings_calendar_with_mis_and_fo.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[14], line 175\u001b[0m, in \u001b[0;36mupdate_excel_sheet\u001b[0;34m(file_path, sheet_name, fo_symbols)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m c_idx, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(row, \u001b[38;5;28mlen\u001b[39m(df\u001b[38;5;241m.\u001b[39mcolumns) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    173\u001b[0m         ws\u001b[38;5;241m.\u001b[39mcell(row\u001b[38;5;241m=\u001b[39mr_idx, column\u001b[38;5;241m=\u001b[39mc_idx, value\u001b[38;5;241m=\u001b[39mvalue)\n\u001b[0;32m--> 175\u001b[0m \u001b[43mapply_styles\u001b[49m\u001b[43m(\u001b[49m\u001b[43mws\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfo_symbols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m wb\u001b[38;5;241m.\u001b[39msave(file_path)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData successfully appended to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in sheet \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msheet_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[14], line 78\u001b[0m, in \u001b[0;36mapply_styles\u001b[0;34m(ws, fo_symbols, n, threshold_high, threshold_mid)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cell\u001b[38;5;241m.\u001b[39mcolumn_letter \u001b[38;5;129;01min\u001b[39;00m pchange_columns:\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cell\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcell\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m:\n\u001b[1;32m     79\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m cell\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m>\u001b[39m threshold_high:\n\u001b[1;32m     80\u001b[0m                 cell\u001b[38;5;241m.\u001b[39mfill \u001b[38;5;241m=\u001b[39m PatternFill(start_color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m00FF00\u001b[39m\u001b[38;5;124m\"\u001b[39m, end_color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m00FF00\u001b[39m\u001b[38;5;124m\"\u001b[39m, fill_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msolid\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: '>' not supported between instances of 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import Font, PatternFill\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "from datetime import datetime\n",
    "\n",
    "# Define the URLs and headers\n",
    "calendar_url = \"https://www.nseindia.com/api/event-calendar\"\n",
    "stock_data_url = \"https://www.nseindia.com/api/equity-stockIndices?index=NIFTY%20TOTAL%20MARKET\"\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3',\n",
    "    'Accept-Language': 'en-US,en;q=0.5',\n",
    "    'Accept-Encoding': 'gzip, deflate, br',\n",
    "    'Connection': 'keep-alive'\n",
    "}\n",
    "\n",
    "# Initialize session to manage cookies\n",
    "session = requests.Session()\n",
    "\n",
    "def fetch_earnings_calendar(url):\n",
    "    try:\n",
    "        session.get('https://www.nseindia.com', headers=headers)\n",
    "        response = session.get(url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        earnings_data = response.json()\n",
    "        parsed_data = [\n",
    "            {\n",
    "                'symbol': item['symbol'],\n",
    "                'Result_date': item['date'],\n",
    "                'Purpose': item['purpose']\n",
    "            }\n",
    "            for item in earnings_data\n",
    "        ]\n",
    "        return pd.DataFrame(parsed_data)\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching earnings calendar: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def load_mis_data(filename):\n",
    "    mis_df = pd.read_excel(filename, sheet_name='MIS')\n",
    "    return mis_df\n",
    "\n",
    "def add_mis_margin(df, mis_df):\n",
    "    merged_df = df.merge(mis_df, left_on='symbol', right_on='Stocks allowed for MIS', how='left')\n",
    "    merged_df.rename(columns={'Margin allowed': 'MIS Margin allowed'}, inplace=True)\n",
    "    merged_df['MIS Margin allowed'] = merged_df['MIS Margin allowed'].fillna('ASM')\n",
    "    merged_df = merged_df.drop(columns=['Stocks allowed for MIS'])\n",
    "    return merged_df\n",
    "\n",
    "def apply_styles(ws, fo_symbols, n=5, threshold_high=3, threshold_mid=1):\n",
    "    header_font = Font(bold=True)\n",
    "    for cell in ws[\"1:1\"]:\n",
    "        cell.font = header_font\n",
    "        cell.fill = PatternFill(start_color=\"FFFF00\", end_color=\"FFFF00\", fill_type=\"solid\")\n",
    "\n",
    "    for col in ws.columns:\n",
    "        max_length = 0\n",
    "        column = col[0].column_letter\n",
    "        for cell in col:\n",
    "            try:\n",
    "                if len(str(cell.value)) > max_length:\n",
    "                    max_length = len(cell.value)\n",
    "            except:\n",
    "                pass\n",
    "        adjusted_width = (max_length + 2)\n",
    "        ws.column_dimensions[column].width = adjusted_width\n",
    "\n",
    "    ws.auto_filter.ref = ws.dimensions\n",
    "    ws.freeze_panes = ws['E2']\n",
    "\n",
    "    pchange_columns = [cell.column_letter for cell in ws[1] if cell.value and 'pChange' in cell.value]\n",
    "\n",
    "    for i, row in enumerate(ws.iter_rows(min_row=2, max_row=ws.max_row), start=2):\n",
    "        for cell in row:\n",
    "            if cell.column_letter in pchange_columns:\n",
    "                if cell.value is not None:\n",
    "                    if cell.value > 0:\n",
    "                        if cell.value > threshold_high:\n",
    "                            cell.fill = PatternFill(start_color=\"00FF00\", end_color=\"00FF00\", fill_type=\"solid\")\n",
    "                        elif cell.value > threshold_mid:\n",
    "                            cell.fill = PatternFill(start_color=\"66FF66\", end_color=\"66FF66\", fill_type=\"solid\")\n",
    "                        else:\n",
    "                            cell.fill = PatternFill(start_color=\"99FF99\", end_color=\"99FF99\", fill_type=\"solid\")\n",
    "                    elif cell.value < 0:\n",
    "                        cell.fill = PatternFill(start_color=\"FF0000\", end_color=\"FF0000\", fill_type=\"solid\")\n",
    "\n",
    "            if cell.column_letter == 'A' and cell.value in fo_symbols:\n",
    "                for highlight_cell in row:\n",
    "                    highlight_cell.fill = PatternFill(start_color=\"FFFF00\", end_color=\"FFFF00\", fill_type=\"solid\")\n",
    "\n",
    "            if (i - 1) % n == 0:\n",
    "                cell.fill = PatternFill(start_color=\"ADD8E6\", end_color=\"ADD8E6\", fill_type=\"solid\")\n",
    "\n",
    "def fetch_fo_list_from_csv(file_path):\n",
    "    try:\n",
    "        fo_symbols_df = pd.read_csv(file_path)\n",
    "        fo_symbols_df.columns = fo_symbols_df.columns.str.strip()\n",
    "        fo_symbols = fo_symbols_df['SYMBOL'].tolist()\n",
    "        return fo_symbols\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching F&O symbols: {e}\")\n",
    "        return []\n",
    "\n",
    "def fetch_stock_data(symbol):\n",
    "    try:\n",
    "        response = session.get(stock_data_url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        stock_data = response.json()['data']\n",
    "\n",
    "        for item in stock_data:\n",
    "            if item['symbol'] == symbol:\n",
    "                return {\n",
    "                    'symbol': item['symbol'],\n",
    "                    'open': item.get('open', ''),\n",
    "                    'dayHigh': item.get('dayHigh', ''),\n",
    "                    'dayLow': item.get('dayLow', ''),\n",
    "                    'lastPrice': item.get('lastPrice', ''),\n",
    "                    'previousClose': item.get('previousClose', ''),\n",
    "                    'pChange': item.get('pChange', ''),\n",
    "                    'totalTradedVolume': item.get('totalTradedVolume', ''),\n",
    "                    'yearHigh': item.get('yearHigh', ''),\n",
    "                    'nearWKH': item.get('nearWKH', ''),\n",
    "                    'perChange30d': item.get('perChange30d', ''),\n",
    "                    'industry': item['meta'].get('industry', '')\n",
    "                }\n",
    "        return None\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching stock data for {symbol}: {e}\")\n",
    "        return None\n",
    "\n",
    "def update_excel_sheet(file_path, sheet_name, fo_symbols):\n",
    "    wb = load_workbook(file_path)\n",
    "    if sheet_name not in wb.sheetnames:\n",
    "        print(f\"Sheet {sheet_name} not found in the workbook.\")\n",
    "        return\n",
    "    \n",
    "    ws = wb[sheet_name]\n",
    "    df = pd.DataFrame(ws.values)\n",
    "\n",
    "    symbols = df[0].dropna().values[1:]\n",
    "\n",
    "    new_rows = []\n",
    "\n",
    "    for symbol in symbols:\n",
    "        stock_data = fetch_stock_data(symbol)\n",
    "        if stock_data:\n",
    "            new_row = [\n",
    "                stock_data['symbol'],\n",
    "                stock_data['open'],\n",
    "                stock_data['dayHigh'],\n",
    "                stock_data['dayLow'],\n",
    "                stock_data['lastPrice'],\n",
    "                stock_data['previousClose'],\n",
    "                stock_data['pChange'],\n",
    "                stock_data['totalTradedVolume'],\n",
    "                stock_data['yearHigh'],\n",
    "                stock_data['nearWKH'],\n",
    "                stock_data['perChange30d'],\n",
    "                stock_data['industry']\n",
    "            ]\n",
    "        else:\n",
    "            new_row = [symbol] + [''] * 11\n",
    "        new_rows.append(new_row)\n",
    "\n",
    "    new_df = pd.DataFrame(new_rows, columns=[\n",
    "        'symbol', 'open', 'dayHigh', 'dayLow', 'lastPrice', 'previousClose',\n",
    "        'pChange', 'totalTradedVolume', 'yearHigh', 'nearWKH', 'perChange30d', 'industry'\n",
    "    ])\n",
    "\n",
    "    for r_idx, row in enumerate(dataframe_to_rows(new_df, index=False, header=True), 1):\n",
    "        for c_idx, value in enumerate(row, len(df.columns) + 1):\n",
    "            ws.cell(row=r_idx, column=c_idx, value=value)\n",
    "\n",
    "    apply_styles(ws, fo_symbols)\n",
    "    wb.save(file_path)\n",
    "    print(f\"Data successfully appended to {file_path} in sheet {sheet_name}.\")\n",
    "\n",
    "# Fetch the earnings calendar data\n",
    "earnings_df = fetch_earnings_calendar(calendar_url)\n",
    "if earnings_df.empty:\n",
    "    print(\"No earnings data fetched.\")\n",
    "    exit()\n",
    "\n",
    "unique_dates = earnings_df['Result_date'].unique()[:5]\n",
    "print(\"Available dates:\")\n",
    "for i, date in enumerate(unique_dates, start=1):\n",
    "    print(f\"{i}. {date}\")\n",
    "\n",
    "selected_dates = []\n",
    "for i in range(0, 5):  # Only ask for 5 dates\n",
    "    date_index = int(input(f\"Enter the serial number of the date you want to save to Sheet {i+1}: \")) - 1\n",
    "    if date_index not in range(5):\n",
    "        print(\"Invalid input. Please run the script again and enter valid serial numbers.\")\n",
    "        exit()\n",
    "    selected_dates.append(unique_dates[date_index])\n",
    "\n",
    "mis_filename = '/Users/tjzoomac/tj_nse/ai_market/01_nifty_live/002/fixed_files_getto/rms.xlsx'\n",
    "mis_data = load_mis_data(mis_filename)\n",
    "\n",
    "fo_csv_path = '/Users/tjzoomac/tj_nse/ai_market/01_nifty_live/002/fixed_files_getto/MW-SECURITIES-IN-F&O-28-Jul-2024.csv'\n",
    "fo_symbols = fetch_fo_list_from_csv(fo_csv_path)\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%d%b\")\n",
    "filename = f'/Users/tjzoomac/tj_nse/ai_market/01_nifty_live/002/database/Aug_24/8 Aug 24/{timestamp}_0900_earnings_calendar_with_mis_and_fo.xlsx'\n",
    "excel_writer = pd.ExcelWriter(filename, engine='openpyxl')\n",
    "\n",
    "# Save data for each selected date in a separate sheet\n",
    "for i, date in enumerate(selected_dates, start=1):\n",
    "    filtered_df = earnings_df[earnings_df['Result_date'] == date]\n",
    "    filtered_df = add_mis_margin(filtered_df, mis_data)\n",
    "    sheet_name = f\"Sheet{i}_{date.replace('-', '_')}\"\n",
    "    filtered_df.to_excel(excel_writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "    # Apply styles to the existing data\n",
    "    wb = excel_writer.book\n",
    "    ws = wb[sheet_name]\n",
    "    apply_styles(ws, fo_symbols)\n",
    "\n",
    "# Save the Excel file first\n",
    "excel_writer.close()\n",
    "\n",
    "# Now reopen the file and append stock data\n",
    "for i, date in enumerate(selected_dates, start=1):\n",
    "    sheet_name = f\"Sheet{i}_{date.replace('-', '_')}\"\n",
    "    update_excel_sheet(filename, sheet_name, fo_symbols)\n",
    "\n",
    "print(\"Data saved to earnings_calendar_with_mis_and_fo.xlsx\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Program 2 : Nifty total and FnO pre market status for the day with MIS margins and IEP values > Pr.Close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       symbol      LTP  pChange      IEP   D_Low   D_High  Pr.Close  \\\n",
      "0   NIRMAN-RE   109.80   21.058   109.80   73.05   115.00     90.70   \n",
      "1   GATECH-RE     0.00   20.000     0.06    0.04     0.15      0.05   \n",
      "2      SAKUMA     7.69   18.673     7.69   14.16    39.29     32.39   \n",
      "3      3PLAND    55.54   18.574    55.54   19.25    46.84     46.84   \n",
      "4  GRWRHITECH  3400.00   17.428  3400.00  893.00  2895.40   2895.40   \n",
      "\n",
      "   Total_Value_Crores  \n",
      "0               0.005  \n",
      "1               0.000  \n",
      "2               0.256  \n",
      "3               0.306  \n",
      "4              17.462  \n",
      "Data updated in 09Aug_09:10_0908_1_nifty_Total_pre_open.xlsx in sheet Nifty Data\n",
      "IEP_Eql_Low data updated in 09Aug_09:10_0908_1_nifty_Total_pre_open.xlsx\n",
      "IEP>Pr.Close data updated in 09Aug_09:10_0908_1_nifty_Total_pre_open.xlsx\n",
      "IEP=L>Pr.Cls data updated in 09Aug_09:10_0908_1_nifty_Total_pre_open.xlsx\n",
      "      symbol      LTP  pChange      IEP   D_Low   D_High  Pr.Close  \\\n",
      "0  EICHERMOT  4805.65    4.998  4805.65  3274.9  5058.90   4576.90   \n",
      "1       ONGC   333.95    3.486   333.95   172.6   344.70    322.70   \n",
      "2      PIIND  4600.00    3.203  4600.00  3220.0  4550.00   4457.25   \n",
      "3       IDEA    16.30    2.774    16.30     7.5    19.18     15.86   \n",
      "4        ABB  8150.00    2.615  8150.00  3850.0  9149.95   7942.30   \n",
      "\n",
      "   Total_Value_Crores  \n",
      "0               5.915  \n",
      "1               6.856  \n",
      "2               1.341  \n",
      "3               3.805  \n",
      "4              10.258  \n",
      "Data updated in 09Aug_09:10_0908_1_nifty_fno_pre_open.xlsx in sheet FO Data\n",
      "IEP_Eql_Low data updated in 09Aug_09:10_0908_1_nifty_fno_pre_open.xlsx\n",
      "IEP>Pr.Close data updated in 09Aug_09:10_0908_1_nifty_fno_pre_open.xlsx\n",
      "IEP=L>Pr.Cls data updated in 09Aug_09:10_0908_1_nifty_fno_pre_open.xlsx\n",
      "MIS Margin allowed column added to 09Aug_09:10_0908_1_nifty_Total_pre_open.xlsx\n",
      "MIS Margin allowed column added to 09Aug_09:10_0908_1_nifty_fno_pre_open.xlsx\n"
     ]
    }
   ],
   "source": [
    "## 1. Program to fetch Nifty Total Pre-Open data and Nifty FO Pre-Open data.\n",
    "## 2. Save the data to Excel files.\n",
    "## 3. Update the data in the Excel files.\n",
    "## 4. Apply color coding to the data in the Excel files.\n",
    "## 5. Apply styles to the data in the Excel files.\n",
    "## 6. Update the filtered data in the Excel files based on the pChange threshold.\n",
    "\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from openpyxl import Workbook, load_workbook\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "from openpyxl.styles import Font, PatternFill\n",
    "from datetime import datetime\n",
    "import os\n",
    "import colorsys\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Initialize session object\n",
    "session = requests.Session()\n",
    "headers = {\n",
    "    'user-agent': \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.4.1 Safari/605.1.15\",\n",
    "}\n",
    "\n",
    "def get_cookie():\n",
    "    url = 'https://www.nseindia.com'\n",
    "    response = session.get(url, headers=headers)\n",
    "    cookies = response.cookies.get_dict()\n",
    "    cookie_str = '; '.join([f\"{key}={value}\" for key, value in cookies.items()])\n",
    "    return cookie_str\n",
    "\n",
    "def fetch_data(url):\n",
    "    retries = 3\n",
    "    for attempt in range(retries):\n",
    "        headers['cookie'] = get_cookie()\n",
    "        try:\n",
    "            response = session.get(url, headers=headers)\n",
    "            response.raise_for_status()\n",
    "            return response.json()\n",
    "        except requests.exceptions.HTTPError as e:\n",
    "            if response.status_code in [401, 403]:\n",
    "                print(f\"Attempt {attempt+1}: Cookie expired. Fetching a new cookie...\")\n",
    "            else:\n",
    "                print(f\"HTTP Error {response.status_code}: {response.text}\")\n",
    "                break\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Request Error: {e}\")\n",
    "            break\n",
    "    return None\n",
    "\n",
    "def clean_value(value):\n",
    "    if isinstance(value, str):\n",
    "        return float(value.replace(',', ''))\n",
    "    return float(value)\n",
    "\n",
    "def extract_data(positions):\n",
    "    data_list = []\n",
    "    for item in positions['data']:\n",
    "        metadata = item['metadata']\n",
    "        detail = item.get('detail', {}).get('preOpenMarket', {})\n",
    "        symbol = metadata['symbol']\n",
    "        ltp = clean_value(metadata.get('lastPrice', 0))\n",
    "        p_change = round(clean_value(metadata.get('pChange', 0)), 3)\n",
    "        iep = clean_value(detail.get('IEP', 0))\n",
    "        day_low = clean_value(metadata.get('yearLow', 0))\n",
    "        day_high = clean_value(metadata.get('yearHigh', 0))\n",
    "        previous_close = clean_value(metadata.get('previousClose', 0))\n",
    "        total_value_crores = round(clean_value(metadata.get('totalTurnover', 0)) / 1e7, 3)\n",
    "        data_list.append([symbol, ltp, p_change, iep, day_low, day_high, previous_close, total_value_crores])\n",
    "    df = pd.DataFrame(data_list, columns=['symbol', 'LTP', 'pChange', 'IEP', 'D_Low', 'D_High', 'Pr.Close', 'Total_Value_Crores'])\n",
    "    return df\n",
    "\n",
    "def append_timestamp_columns(existing_df, new_df):\n",
    "    timestamp = datetime.now().strftime('%H:%M:%S')\n",
    "    new_df_unique = new_df.drop_duplicates(subset='symbol')\n",
    "    existing_df[f'LTP_{timestamp}'] = existing_df['symbol'].map(new_df_unique.set_index('symbol')['LTP'])\n",
    "    existing_df[f'pChange_{timestamp}'] = existing_df['symbol'].map(new_df_unique.set_index('symbol')['pChange'])\n",
    "    return existing_df\n",
    "\n",
    "def calculate_pchange_diff(existing_df, timestamp):\n",
    "    pchange_columns = [col for col in existing_df.columns if col.startswith('pChange_') and col != f'pChange_{timestamp}']\n",
    "    \n",
    "    if pchange_columns:\n",
    "        pchange_columns.sort()\n",
    "        previous_pchange_col = pchange_columns[-1]\n",
    "        \n",
    "        existing_df[f'pChange_Diff_{timestamp}'] = existing_df[f'pChange_{timestamp}'] - existing_df[previous_pchange_col]\n",
    "    \n",
    "    return existing_df\n",
    "\n",
    "def apply_color_coding(ws):\n",
    "    for col in ws.iter_cols(min_col=1, max_col=ws.max_column):\n",
    "        if col[0].value and 'pChange' in col[0].value:\n",
    "            values = [cell.value for cell in col[1:] if cell.value is not None and not pd.isna(cell.value)]\n",
    "            if values:\n",
    "                min_val = min(values)\n",
    "                max_val = max(values)\n",
    "                for cell in col[1:]:\n",
    "                    if cell.value is not None and not pd.isna(cell.value):\n",
    "                        norm_value = (cell.value - min_val) / (max_val - min_val) if max_val != min_val else 0\n",
    "                        if cell.value > 0:\n",
    "                            hue = 120\n",
    "                            saturation = norm_value * 100\n",
    "                            lightness = 50\n",
    "                        else:\n",
    "                            hue = 0\n",
    "                            saturation = abs(norm_value) * 100\n",
    "                            lightness = 50\n",
    "                        rgb_color = colorsys.hls_to_rgb(hue / 360, lightness / 100, saturation / 100)\n",
    "                        hex_color = '{:02X}{:02X}{:02X}'.format(int(rgb_color[0] * 255), int(rgb_color[1] * 255), int(rgb_color[2] * 255))\n",
    "                        cell.fill = PatternFill(start_color=hex_color, end_color=hex_color, fill_type=\"solid\")\n",
    "                        \n",
    "    for col in ws.iter_cols(min_col=1, max_col=ws.max_column):\n",
    "        if col[0].value == 'Total_Value_Crores':\n",
    "            values = [cell.value for cell in col[1:] if cell.value is not None and not pd.isna(cell.value)]\n",
    "            if values:\n",
    "                min_val = min(values)\n",
    "                max_val = max(values)\n",
    "                for cell in col[1:]:\n",
    "                    if cell.value is not None and not pd.isna(cell.value):\n",
    "                        norm_value = (cell.value - min_val) / (max_val - min_val) if max_val != min_val else 0\n",
    "                        hue = 240\n",
    "                        saturation = norm_value * 100\n",
    "                        lightness = 50\n",
    "                        rgb_color = colorsys.hls_to_rgb(hue / 360, lightness / 100, saturation / 100)\n",
    "                        hex_color = '{:02X}{:02X}{:02X}'.format(int(rgb_color[0] * 255), int(rgb_color[1] * 255), int(rgb_color[2] * 255))\n",
    "                        cell.fill = PatternFill(start_color=hex_color, end_color=hex_color, fill_type=\"solid\")\n",
    "        \n",
    "        # Apply color coding for 'MIS Margin allowed' column\n",
    "        if col[0].value == 'MIS Margin allowed':\n",
    "            for cell in col[1:]:\n",
    "                if cell.value == '5X':\n",
    "                    cell.fill = PatternFill(start_color=\"00FF00\", end_color=\"00FF00\", fill_type=\"solid\")\n",
    "\n",
    "def apply_styles(ws):\n",
    "    header_font = Font(bold=True)\n",
    "    for cell in ws[\"1:1\"]:\n",
    "        cell.font = header_font\n",
    "        cell.fill = PatternFill(start_color=\"FFFF00\", end_color=\"FFFF00\", fill_type=\"solid\")\n",
    "\n",
    "    for col in ws.columns:\n",
    "        max_length = 0\n",
    "        column = col[0].column_letter\n",
    "        for cell in col:\n",
    "            try:\n",
    "                if len(str(cell.value)) > max_length:\n",
    "                    max_length = len(cell.value)\n",
    "            except:\n",
    "                pass\n",
    "        adjusted_width = (max_length + 2)\n",
    "        ws.column_dimensions[column].width = adjusted_width\n",
    "\n",
    "    ws.auto_filter.ref = ws.dimensions\n",
    "    ws.freeze_panes = ws['B2']\n",
    "\n",
    "    apply_color_coding(ws)\n",
    "\n",
    "def save_to_excel(df, filename, sheet_name):\n",
    "    if os.path.exists(filename):\n",
    "        wb = load_workbook(filename)\n",
    "        if sheet_name in wb.sheetnames:\n",
    "            ws = wb[sheet_name]\n",
    "            data = ws.values\n",
    "            columns = next(data)[0:]\n",
    "            existing_df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "            timestamp = datetime.now().strftime('%H:%M:%S')\n",
    "            existing_df = append_timestamp_columns(existing_df, df)\n",
    "            existing_df = calculate_pchange_diff(existing_df, timestamp)\n",
    "\n",
    "            for row in ws.iter_rows(min_row=2, max_row=ws.max_row, min_col=1, max_col=ws.max_column):\n",
    "                for cell in row:\n",
    "                    cell.value = None\n",
    "        else:\n",
    "            ws = wb.create_sheet(title=sheet_name)\n",
    "            existing_df = df\n",
    "            for col_num, column_title in enumerate(existing_df.columns, 1):\n",
    "                ws.cell(row=1, column=col_num, value=column_title)\n",
    "    else:\n",
    "        wb = Workbook()\n",
    "        ws = wb.active\n",
    "        ws.title = sheet_name\n",
    "        existing_df = df\n",
    "        for col_num, column_title in enumerate(existing_df.columns, 1):\n",
    "            ws.cell(row=1, column=col_num, value=column_title)\n",
    "\n",
    "    for col_num, column_title in enumerate(existing_df.columns, 1):\n",
    "        ws.cell(row=1, column=col_num, value=column_title)\n",
    "\n",
    "    for r_idx, row in existing_df.iterrows():\n",
    "        for c_idx, value in enumerate(row):\n",
    "            ws.cell(row=r_idx + 2, column=c_idx + 1, value=value)\n",
    "\n",
    "    apply_styles(ws)\n",
    "    wb.save(filename)\n",
    "    print(f\"Data updated in {filename} in sheet {sheet_name}\")\n",
    "\n",
    "def update_filtered_data(df, filename, sheet_name, filter_condition, pchange_threshold):\n",
    "    filtered_df = df[filter_condition & (df['pChange'] > pchange_threshold)]\n",
    "\n",
    "    if os.path.exists(filename):\n",
    "        wb = load_workbook(filename)\n",
    "        if sheet_name in wb.sheetnames:\n",
    "            ws_filtered = wb[sheet_name]\n",
    "            data = ws_filtered.values\n",
    "            columns = next(data)[0:]\n",
    "            existing_df = pd.DataFrame(data, columns=columns)\n",
    "            timestamp = datetime.now().strftime('%H:%M:%S')\n",
    "            existing_df = append_timestamp_columns(existing_df, filtered_df)\n",
    "            existing_df = calculate_pchange_diff(existing_df, timestamp)\n",
    "\n",
    "            for row in ws_filtered.iter_rows(min_row=2, max_row=ws_filtered.max_row, min_col=1, max_col=ws_filtered.max_column):\n",
    "                for cell in row:\n",
    "                    cell.value = None\n",
    "        else:\n",
    "            ws_filtered = wb.create_sheet(title=sheet_name)\n",
    "            existing_df = filtered_df\n",
    "            for col_num, column_title in enumerate(existing_df.columns, 1):\n",
    "                ws_filtered.cell(row=1, column=col_num, value=column_title)\n",
    "    else:\n",
    "        wb = Workbook()\n",
    "        ws_filtered = wb.active\n",
    "        ws_filtered.title = sheet_name\n",
    "        existing_df = filtered_df\n",
    "        for col_num, column_title in enumerate(existing_df.columns, 1):\n",
    "            ws_filtered.cell(row=1, column=col_num, value=column_title)\n",
    "\n",
    "    for r_idx, row in existing_df.iterrows():\n",
    "        for c_idx, value in enumerate(row):\n",
    "            ws_filtered.cell(row=r_idx + 2, column=c_idx + 1, value=value)\n",
    "\n",
    "    apply_styles(ws_filtered)\n",
    "    wb.save(filename)\n",
    "    print(f\"{sheet_name} data updated in {filename}\")\n",
    "\n",
    "def fetch_and_save_nifty_total_pre_open(pchange_threshold):\n",
    "    nifty_url = 'https://www.nseindia.com/api/market-data-pre-open?key=ALL'\n",
    "    while True:\n",
    "        nifty_data = fetch_data(nifty_url)\n",
    "        if nifty_data:\n",
    "            df = extract_data(nifty_data)\n",
    "            print(df.head())\n",
    "\n",
    "            # Define the Excel filename\n",
    "            excel_filename = f'{datetime.now().strftime(\"%d%b_%H:%M\")}_0908_1_nifty_Total_pre_open.xlsx'\n",
    "\n",
    "            # Save the main DataFrame to the Nifty Data sheet\n",
    "            save_to_excel(df, excel_filename, 'Nifty Data')\n",
    "\n",
    "            # Update the filtered data sheets\n",
    "            update_filtered_data(df, excel_filename, 'IEP_Eql_Low', df['IEP'] == df['D_Low'], pchange_threshold)\n",
    "            update_filtered_data(df, excel_filename, 'IEP>Pr.Close', df['IEP'] > df['Pr.Close'], pchange_threshold)\n",
    "            update_filtered_data(df, excel_filename, 'IEP=L>Pr.Cls', (df['IEP'] == df['D_Low']) & (df['IEP'] > df['Pr.Close']), pchange_threshold)\n",
    "            break\n",
    "        else:\n",
    "            print(\"Failed to fetch Nifty Total Pre-Open data, retrying...\")\n",
    "\n",
    "def fetch_and_save_nifty_fo_pre_open(pchange_threshold):\n",
    "    fo_url = 'https://www.nseindia.com/api/market-data-pre-open?key=FO'\n",
    "    while True:\n",
    "        fo_data = fetch_data(fo_url)\n",
    "        if fo_data:\n",
    "            df_fo = extract_data(fo_data)\n",
    "            print(df_fo.head())\n",
    "\n",
    "            # Define the new Excel filename\n",
    "            fo_excel_filename = f'{datetime.now().strftime(\"%d%b_%H:%M\")}_0908_1_nifty_fno_pre_open.xlsx'\n",
    "\n",
    "            # Save the FO DataFrame to a new sheet\n",
    "            save_to_excel(df_fo, fo_excel_filename, 'FO Data')\n",
    "\n",
    "            # Update the filtered data sheets for the new URL\n",
    "            update_filtered_data(df_fo, fo_excel_filename, 'IEP_Eql_Low', df_fo['IEP'] == df_fo['D_Low'], pchange_threshold)\n",
    "            update_filtered_data(df_fo, fo_excel_filename, 'IEP>Pr.Close', df_fo['IEP'] > df_fo['Pr.Close'], pchange_threshold)\n",
    "            update_filtered_data(df_fo, fo_excel_filename, 'IEP=L>Pr.Cls', (df_fo['IEP'] == df_fo['D_Low']) & (df_fo['IEP'] > df_fo['Pr.Close']), pchange_threshold)\n",
    "            break\n",
    "        else:\n",
    "            print(\"Failed to fetch Nifty FO Pre-Open data, retrying...\")\n",
    "\n",
    "# Load the pre-saved Excel file and extract the data from 'MIS' sheet\n",
    "def load_mis_data(filename):\n",
    "    mis_df = pd.read_excel(filename, sheet_name='MIS')\n",
    "    return mis_df\n",
    "\n",
    "def add_mis_margin(df, mis_df):\n",
    "    # Use merge to join on 'symbol' and 'Stocks allowed for MIS'\n",
    "    merged_df = df.merge(mis_df, left_on='symbol', right_on='Stocks allowed for MIS', how='left')\n",
    "    # Rename the column for clarity\n",
    "    merged_df.rename(columns={'Margin allowed': 'MIS Margin allowed'}, inplace=True)\n",
    "    # Fill missing values with \"ASM\"\n",
    "    merged_df['MIS Margin allowed'] = merged_df['MIS Margin allowed'].fillna('ASM')\n",
    "    # Drop the duplicate 'Stocks allowed for MIS' column if needed\n",
    "    merged_df = merged_df.drop(columns=['Stocks allowed for MIS'])\n",
    "    return merged_df\n",
    "\n",
    "# Adding MIS Margin allowed to the output files\n",
    "def add_mis_to_output_files(output_filename):\n",
    "    wb = load_workbook(output_filename)\n",
    "    for sheet_name in wb.sheetnames:\n",
    "        ws = wb[sheet_name]\n",
    "        data = ws.values\n",
    "        columns = next(data)[0:]\n",
    "        existing_df = pd.DataFrame(data, columns=columns)\n",
    "        existing_df = add_mis_margin(existing_df, mis_data)\n",
    "\n",
    "        # Write the header\n",
    "        for col_num, column_title in enumerate(existing_df.columns, 1):\n",
    "            ws.cell(row=1, column=col_num, value=column_title)\n",
    "\n",
    "        # Write the data\n",
    "        for r_idx, row in existing_df.iterrows():\n",
    "            for c_idx, value in enumerate(row):\n",
    "                ws.cell(row=r_idx + 2, column=c_idx + 1, value=value)\n",
    "        apply_styles(ws)\n",
    "    wb.save(output_filename)\n",
    "    print(f\"MIS Margin allowed column added to {output_filename}\")\n",
    "\n",
    "# Prompt the user to input the pChange threshold\n",
    "pchange_threshold = float(input(\"Enter the pChange threshold: \"))\n",
    "\n",
    "# Fetch and save Nifty Total Pre-Open data\n",
    "fetch_and_save_nifty_total_pre_open(pchange_threshold)\n",
    "\n",
    "# Fetch and save Nifty FO Pre-Open data\n",
    "fetch_and_save_nifty_fo_pre_open(pchange_threshold)\n",
    "\n",
    "# Load the pre-saved Excel file and extract the MIS data\n",
    "mis_filename = '/Users/tjzoomac/tj_nse/ai_market/01_nifty_live/002/fixed_files_getto/rms.xlsx'\n",
    "mis_data = load_mis_data(mis_filename)\n",
    "\n",
    "# Update the output files with MIS Margin allowed column\n",
    "output_files = [\n",
    "    f'{datetime.now().strftime(\"%d%b_%H:%M\")}_0908_1_nifty_Total_pre_open.xlsx',\n",
    "    f'{datetime.now().strftime(\"%d%b_%H:%M\")}_0908_1_nifty_fno_pre_open.xlsx'\n",
    "]\n",
    "\n",
    "for output_file in output_files:\n",
    "    add_mis_to_output_files(output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deep_Learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
