{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prog 3: 0915 Hrs Nifty_Total Status with LTP\n",
    "## Sheet 2 : Pchange comparison timestamp(tbdone)\n",
    "## Sheet 3: Ranking system (To be corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, time as dt_time\n",
    "import schedule\n",
    "import time\n",
    "import openpyxl\n",
    "import os\n",
    "from openpyxl.styles import Font, PatternFill\n",
    "\n",
    "# Initialize session object\n",
    "session = requests.Session()\n",
    "headers = {\n",
    "    'user-agent': \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.4.1 Safari/605.1.15\",\n",
    "}\n",
    "\n",
    "def get_cookie():\n",
    "    url = 'https://www.nseindia.com'\n",
    "    response = session.get(url, headers=headers)\n",
    "    cookies = response.cookies.get_dict()\n",
    "    cookie_str = '; '.join([f\"{key}={value}\" for key, value in cookies.items()])\n",
    "    return cookie_str\n",
    "\n",
    "def fetch_nifty_data():\n",
    "    if 'cookie' not in headers or headers['cookie'] is None:\n",
    "        headers['cookie'] = get_cookie()\n",
    "    try:\n",
    "        response = session.get('https://www.nseindia.com/api/equity-stockIndices?index=NIFTY%20TOTAL%20MARKET', headers=headers)\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        if response.status_code == 401:\n",
    "            print(\"Cookie expired. Fetching a new cookie...\")\n",
    "            headers['cookie'] = get_cookie()\n",
    "            return fetch_nifty_data()\n",
    "        else:\n",
    "            print(f\"HTTP Error {response.status_code}: {response.text}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Request Error: {e}\")\n",
    "    return None\n",
    "\n",
    "def clean_value(value):\n",
    "    if isinstance(value, str):\n",
    "        return float(value.replace(',', ''))\n",
    "    return float(value)\n",
    "\n",
    "def extract_data(positions):\n",
    "    data_list = []\n",
    "    for item in positions['data']:\n",
    "        symbol = item['symbol']\n",
    "        ltp = clean_value(item['lastPrice'])\n",
    "        p_change = clean_value(item['pChange'])\n",
    "        open_price = clean_value(item['open'])\n",
    "        day_low = clean_value(item['dayLow'])\n",
    "        day_high = clean_value(item['dayHigh'])\n",
    "        previous_close = clean_value(item['previousClose'])\n",
    "        data_list.append([symbol, ltp, p_change, open_price, day_low, day_high, previous_close])\n",
    "    df = pd.DataFrame(data_list, columns=['symbol', 'LTP', 'pChange', 'Open', 'D_Low', 'D_High', 'Pr.Close'])\n",
    "    return df\n",
    "\n",
    "def append_timestamp_columns(existing_df, new_df):\n",
    "    timestamp = datetime.now().strftime('%H_%M_%S')\n",
    "    existing_df[f'LTP_{timestamp}'] = existing_df['symbol'].map(new_df.set_index('symbol')['LTP'])\n",
    "    existing_df[f'pChange_{timestamp}'] = existing_df['symbol'].map(new_df.set_index('symbol')['pChange'])\n",
    "    return existing_df\n",
    "\n",
    "def calculate_pchange_diff(existing_df, timestamp):\n",
    "    pchange_columns = [col for col in existing_df.columns if col.startswith('pChange_') and col != f'pChange_{timestamp}']\n",
    "    \n",
    "    if pchange_columns:\n",
    "        pchange_columns.sort()\n",
    "        previous_pchange_col = pchange_columns[-1]\n",
    "        existing_df[f'Diff_{timestamp}'] = existing_df[f'pChange_{timestamp}'] - existing_df[previous_pchange_col]\n",
    "    \n",
    "    return existing_df\n",
    "\n",
    "def apply_styles(ws):\n",
    "    # Apply styles to the header\n",
    "    header_font = Font(bold=True)\n",
    "    for cell in ws[\"1:1\"]:\n",
    "        cell.font = header_font\n",
    "        cell.fill = PatternFill(start_color=\"FFFF00\", end_color=\"FFFF00\", fill_type=\"solid\")\n",
    "\n",
    "    # Adjust column widths\n",
    "    for col in ws.columns:\n",
    "        max_length = 0\n",
    "        column = col[0].column_letter  # Get the column name\n",
    "        for cell in col:\n",
    "            try:\n",
    "                if len(str(cell.value)) > max_length:\n",
    "                    max_length = len(cell.value)\n",
    "            except:\n",
    "                pass\n",
    "        adjusted_width = (max_length + 2)\n",
    "        ws.column_dimensions[column].width = adjusted_width\n",
    "\n",
    "    # Apply filter to the first row\n",
    "    ws.auto_filter.ref = ws.dimensions\n",
    "\n",
    "    # Freeze the header row and the first column\n",
    "    ws.freeze_panes = ws['B2']  # This will freeze the first row and the first column\n",
    "\n",
    "def save_to_csv(df, filename):\n",
    "    if os.path.exists(filename):\n",
    "        existing_df = pd.read_csv(filename)\n",
    "        timestamp = datetime.now().strftime('%H_%M_%S')\n",
    "        existing_df = append_timestamp_columns(existing_df, df)\n",
    "        existing_df = calculate_pchange_diff(existing_df, timestamp)\n",
    "    else:\n",
    "        existing_df = df\n",
    "\n",
    "    existing_df.to_csv(filename, index=False)\n",
    "    print(f\"Data updated in {filename} at {datetime.now().strftime('%d%b_%H:%M:%S')}\")\n",
    "\n",
    "def update_filtered_data_csv(df, filename, filter_condition):\n",
    "    if os.path.exists(filename):\n",
    "        existing_df = pd.read_csv(filename)\n",
    "        timestamp = datetime.now().strftime('%H_%M_%S')\n",
    "        filtered_df = df[filter_condition]\n",
    "        existing_df = append_timestamp_columns(existing_df, filtered_df)\n",
    "        existing_df = calculate_pchange_diff(existing_df, timestamp)\n",
    "    else:\n",
    "        existing_df = df[filter_condition]\n",
    "\n",
    "    existing_df.to_csv(filename, index=False)\n",
    "    # print(f\"Filtered data updated in {filename}\")\n",
    "\n",
    "def merge_csv_files_to_excel(csv_files, excel_filename, sheet_names):\n",
    "    with pd.ExcelWriter(excel_filename, engine='openpyxl') as writer:\n",
    "        for csv_file, sheet_name in zip(csv_files, sheet_names):\n",
    "            df = pd.read_csv(csv_file)\n",
    "            df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "            apply_styles(writer.sheets[sheet_name])\n",
    "            apply_color_coding(writer.sheets[sheet_name])\n",
    "            # print(f\"Data from {csv_file} saved to {excel_filename} in sheet {sheet_name}\")\n",
    "\n",
    "def apply_color_coding(ws):\n",
    "    pchange_columns = [cell.column for cell in ws[1] if cell.value and cell.value.startswith('pChange')]\n",
    "    \n",
    "    for col in pchange_columns:\n",
    "        values = []\n",
    "        for cell in ws.iter_cols(min_col=col, max_col=col, min_row=2):\n",
    "            try:\n",
    "                values.append(float(cell[0].value))\n",
    "            except (TypeError, ValueError):\n",
    "                continue\n",
    "        if not values:\n",
    "            continue\n",
    "        \n",
    "        min_value, max_value = min(values), max(values)\n",
    "        range_value = max_value - min_value if max_value != min_value else 1\n",
    "        \n",
    "        for row in ws.iter_rows(min_row=2, max_row=ws.max_row, min_col=col, max_col=col):\n",
    "            for cell in row:\n",
    "                try:\n",
    "                    value = float(cell.value)\n",
    "                    normalized_value = (value - min_value) / range_value\n",
    "                    if value > 0:\n",
    "                        shade = int(204 + 51 * normalized_value)\n",
    "                        hex_color = f\"{shade:02X}FF{shade:02X}\"  # Green shades\n",
    "                        cell.fill = PatternFill(start_color=hex_color, end_color=hex_color, fill_type=\"solid\")\n",
    "                    elif value < 0:\n",
    "                        shade = int(204 + 51 * abs(normalized_value))\n",
    "                        hex_color = f\"FF{shade:02X}{shade:02X}\"  # Red shades\n",
    "                        cell.fill = PatternFill(start_color=hex_color, end_color=hex_color, fill_type=\"solid\")\n",
    "                except (TypeError, ValueError):\n",
    "                    continue\n",
    "\n",
    "def job():\n",
    "    current_time = datetime.now().time()\n",
    "    if ((current_time >= dt_time(0, 15) and current_time <= dt_time(9, 40) and current_time.minute % 1 == 0) or \n",
    "        (current_time > dt_time(9, 40) and current_time < dt_time(10, 45) and current_time.minute % 3 == 0) or \n",
    "        (current_time > dt_time(10, 45) and current_time < dt_time(14, 0) and current_time.minute % 1 == 0) or \n",
    "        (current_time >= dt_time(14, 0) and current_time <= dt_time(15, 30) and current_time.minute % 1 == 0)):\n",
    "\n",
    "        nifty_data = fetch_nifty_data()\n",
    "        if nifty_data:\n",
    "            df = extract_data(nifty_data)\n",
    "            # print(df.head())\n",
    "\n",
    "            # Save individual CSV files\n",
    "            csv_files = ['6_nifty_total_5_min.csv', '6_Open_Eql_Low.csv', '6_Open_Pr.Close.csv', '6_O_L_Pr.Close.csv', '6_Open_D_High.csv']\n",
    "            sheet_names = ['Nifty Data', 'O=L', 'O>Pr.Close', 'O=L<Pr.Close', 'O=D_High']\n",
    "            save_to_csv(df, csv_files[0])\n",
    "            update_filtered_data_csv(df, csv_files[1], df['Open'] == df['D_Low'])\n",
    "            update_filtered_data_csv(df, csv_files[2], df['Open'] > df['Pr.Close'])\n",
    "            update_filtered_data_csv(df, csv_files[3], (df['Open'] == df['D_Low']) & (df['Open'] > df['Pr.Close']))\n",
    "            update_filtered_data_csv(df, csv_files[4], df['Open'] == df['D_High'])\n",
    "\n",
    "            # Merge CSV files into one Excel workbook with different sheets\n",
    "            merge_csv_files_to_excel(csv_files, '6_Nifty_total_csv_to_excel_5_min.xlsx', sheet_names)\n",
    "\n",
    "# Schedule the job every 30 seconds\n",
    "schedule.every(30).seconds.do(job)\n",
    "\n",
    "# Run the scheduler\n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deep_Learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
